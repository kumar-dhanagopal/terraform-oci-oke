= Terraform Options
:idprefix:
:idseparator: -
:sectlinks:
:sectnums:
:uri-repo: https://github.com/oracle-terraform-modules/terraform-oci-oke

:uri-rel-file-base: link:{uri-repo}/blob/master
:uri-rel-tree-base: link:{uri-repo}/tree/master
:uri-calico: https://www.projectcalico.org/
:uri-calico-policy: https://docs.projectcalico.org/v3.8/getting-started/kubernetes/installation/other
:uri-cert-manager: https://cert-manager.readthedocs.io/en/latest/
:uri-docs: {uri-rel-file-base}/docs
:uri-helm: https://helm.sh/
:uri-helm-incubator: https://kubernetes-charts-incubator.storage.googleapis.com/
:uri-helm-jetstack: https://charts.jetstack.io
:uri-kubernetes-hpa: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
:uri-metrics-server: https://github.com/kubernetes-incubator/metrics-server
:uri-oci-images: https://docs.cloud.oracle.com/iaas/images/
:uri-oci-kms: https://docs.cloud.oracle.com/iaas/Content/KeyManagement/Concepts/keyoverview.htm
:uri-oci-loadbalancer-annotations: https://github.com/oracle/oci-cloud-controller-manager/blob/master/docs/load-balancer-annotations.md
:uri-oci-region: https://docs.cloud.oracle.com/iaas/Content/General/Concepts/regions.htm
:uri-terraform-cidrsubnet: https://www.terraform.io/docs/configuration/functions/cidrsubnet.html
:uri-topology: {uri-docs}/topology.adoc

Configuration Terraform Options:

. link:#identity-and-access[Identity and Access]
. link:#ssh-keys[SSH Keys]
. link:#general-oci[General OCI]
. link:#oci-networking[OCI Networking]
. link:#bastion-host[Bastion Host]
. link:#oke[OKE]
. link:#oke-load-balancers[OKE Load Balancers]
. link:#ocir[OCIR]
. link:#helm[Helm]
. link:#calico[Calico]
. link:#kubernetes-metrics-server[Kubernetes Metrics Server]
. link:#kms-integration[KMS integration]

== Identity and access

[stripes=odd,cols="1d,4d,3a,3a", options=header,width="100%"] 
|===
|Parameter
|Description
|Values
|Default

|api_fingerprint
|ssl fingerprint of api public key. *Required*
|
|None

|api_private_key_path
|path to api private key. *Required*
|
|None

|compartment_id
|Compartment id where the OKE Cluster will be provisioned. *Required*
|
|None

|tenancy_id
|Tenancy id of the user. *Required*
|
|None

|user_id
|User's id. *Required*
|
|None

|===

== SSH Keys

[stripes=odd,cols="1d,4d,3a,3a", options=header,width="100%"] 
|===
|Parameter
|Description
|Values
|Default

|ssh_private_key_path
|path to ssh private key. The same key will be used to access worker nodes using SSH. *Required* if bastion is enabled.

|
|None

|ssh_public_key_path
|path to ssh public key. The same key will be used to access worker nodes using SSH. *Required* if bastion is enabled.
|
|None

|===

== General OCI

[stripes=odd,cols="1d,4d,3a,3a", options=header,width="100%"] 
|===
|Parameter
|Description
|Values
|Default

|label_prefix
|a string to be prepended to the name of resources.
|
|oke

|region
|Region where to provision the OKE cluster. {uri-oci-region}[List of regions]. *Required*
|
|us-phoenix-1

|===

== OCI Networking

[stripes=odd,cols="1d,4d,3a,3a", options=header,width="100%"] 
|===
|Parameter
|Description
|Values
|Default


|vcn_name
|The name of the VCN that will be appended to the label_prefix.
|
|oke vcn

|vcn_cidr
|The VCN's CIDR block. The CIDR block specified for the VCN must not overlap with the CIDR block specified for the Kubernetes services (specified with _services_cidr_ parameter).
|
|10.0.0.0/16

|vcn_dns_label
|The internal DNS domain for resources created and prepended to "oraclevcn.com" which is the VCN-internal domain name.
|
|oke

|create_nat_gateway
|Whether to create a NAT gateway. *Required* for private worker mode.
|true/false
|true

|nat_gateway_name
|The NAT gateway name. Appended to the label_prefix.
| 
|nat

|create_service_gateway
|Whether to create a Service Gateway to use Oracle Services.
|true/false
|true

|service_gateway_name
|The Service gateway name. Appended to the label_prefix
| 
|sg

|newbits
|The difference between the VCN's netmask and the desired subnets' masks specified in the form of a map. The values of the map are used as the newbits parameter in the {uri-terraform-cidrsubnet}[cidrsubnet] Terraform function to calculate each subnet's mask. CIDR blocks for workers and load balancer subnets must not overlap with the CIDR blocks for Kubernetes pods (specified with _pods_cidr_ parameter).
|e.g.
[source]
----
newbits = {
  "bastion" = 13
  "lb"      = 11
  "workers" = 2
}
----
|
[source]
----
newbits = {
  "bastion" = 13
  "lb"      = 11
  "workers" = 2
}
----

|subnets
|0-based index of the subnets when the VCN's CIDR is masked with the corresponding newbit value and specified in the form of a map. Used to define the boundaries of the subnets. The values of the map are used as the netnum parameter in the {uri-terraform-cidrsubnet}[cidrsubnet] Terraform function. CIDR blocks for workers and load balancer subnets must not overlap with the CIDR blocks for Kubernetes pods (specified with _pods_cidr_ parameter).
|e.g.
[source]
----
subnets = {
  "bastion" = 32
  "int_lb"  = 16
  "pub_lb"  = 17
  "workers" = 1
}
----
|
[source]
----
subnets = {
  "bastion" = 32
  "int_lb"  = 16
  "pub_lb"  = 17
  "workers" = 1
}
----


|===

== Bastion Host

[stripes=odd,cols="1d,4d,3a,3a", options=header,width="100%"] 
|===
|Parameter
|Description
|Values
|Default

|create_bastion
|Whether to create the bastion host.
|true/false
|true

|bastion_shape
|The shape of bastion instance.
|
|VM.Standard.E2.1

|bastion_access
|CIDR block in the form of a string to which ssh access to the bastion must be restricted to. *_ANYWHERE_* is equivalent to 0.0.0.0/0 and allows ssh access from anywhere.
|XXX.XXX.XXX.XXX/YY
|ANYWHERE

|enable_instance_principal
|Whether to enable instance_principal on the bastion. Refer to {uri-docs}/instructions.adoc/#enabling-instance_principal-on-the-bastion-host[instance_principal]
|
|

|availability_domains
|The Availability Domain where to provision non-OKE resources e.g. bastion host. This is specified in the form of a map.
| e.g.
[source]
----
availability_domains = {
  "bastion"     = 1
}
----
|
[source]
----
  "bastion"     = 1
----

|bastion_package_upgrade
|Whether to upgrade the instance on first boot. If you choose Ubuntu for the bastion and you set this to true, also set the package_update to true as well.
|true/false
|true

|===

== OKE

[stripes=odd,cols="1d,3d,3a,3a", options=header,width="100%"] 
|===
|Parameter
|Description
|Values
|Default

|cluster_name
|The name of the OKE cluster. This will be appended to the label_prefix.
|
|oke

|worker_mode
|Whether the worker nodes should be public or private. Private requires NAT gateway.
|private/public
|private

|allow_node_port_access
|Whether to allow access to NodePort services when worker nodes are deployed in public mode.
|true/false
|false


|allow_worker_ssh_access
|Whether to allow ssh access to worker nodes. Even if worker nodes are deployed in public mode, ssh access to worker nodes requires going through the bastion host.
|true/false
|false

|dashboard_enabled
|Whether to create the default Kubernetes dashboard.
|true/false
|true

|kubernetes_version
|The version of Kubernetes to provision. This is based on the available versions in OKE. By default, the available versions will be queries and the latest version selected. To provision a specific version, choose from available versions and override the 'LATEST' value.
|LATEST,v1.11.9, v1.12.7
|LATEST

|node_pools
|The number, shape and quantities per subnets of node pools to create. Each key and tuple pair corresponds to 1 node pool. The first parameter in the tuple sets the shape of the worker node and the 2nd parameter sets the size of the node pool. A minimum of 3 worker worker nodes per node pool will be created.  Refer to {uri-topology}[topology] for more thorough examples.
|e.g.
[source]
----
node_pools = {
  "np1" = ["VM.Standard2.1", 1]
}
----
|----
node_pools = {
  "np1" = ["VM.Standard2.1", 1]
}
----

|node_pool_name_prefix
|A string prefixed to the node pool name.
|
|np

|node_pool_image_id
|The OCID of custom image to use when provisioning worker nodes. When no OCID is specified, the worker nodes will use the node_pool_os and node_pool_os_version to identify an image to provision the worker nodes.
|
|NONE

|node_pool_os
|The name of the Operating System image to use to provision the worker nodes.
|
|Oracle Linux

|node_pool_os_version
|The corresponding version of the Operating System image to use to provision the worker nodes.
|
|7.6

|pods_cidr
|The CIDR for the Kubernetes POD network for flannel networking. CIDR blocks for pods must not overlap with the CIDR blocks for workers and load balancer subnets (calculated using vcn_cidr, newbits and subnets parameters).
|
|10.244.0.0/16

|services_cidr
|The CIDR for the Kubernetes services network. The CIDR block specified for the Kubernetes services must not overlap with the CIDR block specified for the VCN CIDR.
|
|10.96.0.0/16

|tiller_enabled
|Whether to install the server side of Helm in the OKE cluster.
|true/false
|true

|===

== OKE Load Balancers

[stripes=odd,cols="1d,3d,3a,3a", options=header,width="100%"] 
|===
|Parameter
|Description
|Values
|Default

|lb_subnet_type
|The type of load balancer subnets to create. 

Even if you set the load balancer subnets to be internal, you still need to set the correct {uri-oci-loadbalancer-annotations}[annotations] when creating internal load balancers. Just setting the subnet to be private is *_not_* sufficient.

Refer to {uri-topology}[topology] for more thorough examples.
|both, internal, public
|public

|preferred_lb_subnets
|The preferred load balancer subnets that OKE will automatically choose when creating load balancers. If 'public' is chosen, the value for lb_subnet_type must be either 'public' or 'both'. If 'private' is chosen, the value for lb_subnet_type must be either 'internal' or 'both'.

Even if you set the load balancer subnets to be internal, you still need to set the correct {uri-oci-loadbalancer-annotations}[annotations] when creating internal load balancers. Just setting the subnet to be private is *_not_* sufficient.

Refer to {uri-topology}[topology] for more thorough examples.

|internal/public
|public

|===

== OCIR

[stripes=odd,cols="1d,4d,3a,3a", options=header,width="100%"] 
|===
|Parameter
|Description
|Values
|Default

|create_auth_token
|Whether to create an Auth Token. The Auth Token is then subsequently used to create a Kubernetes secret, which can then be used as an imagePullSecrets in a deployment.
|true/false
|false

|email_address
|The email address to be used when creating the Docker secret. *Required* if create_auth_token is set to true.
|
|None

|tenancy_name
|The *_name_* of the tenancy to be used when creating the Docker secret.  This is different from tenancy_id. *Required* if create_auth_token is set to true.
|
|None

|username
|The username that can login to the selected tenancy. This is different from tenancy_id. *Required* if create_auth_token is set to true.

|
|None

|===

== Helm

[stripes=odd,cols="1d,4d,3a,3a", options=header,width="100%"] 
|===
|Parameter
|Description
|Values
|Default

|add_incubator_repo
|Whether to add the {uri-helm-incubator}[incubator] repo to the bastion's local helm repo.
|true/false
|false

|add_jetstack_repo
|Whether to add the {uri-helm-jetstack}[jetstack] repo to the bastion's local helm repo. *Required* for {uri-cert-manager}[cert-manager].
|true/false
|false

|helm_version
|The version of the {uri-helm}[helm] client to install on the bastion. A subsequent upgrade of tiller (server-side helm) will then be automatically performed.
|
|2.14.3

|install_helm
|Whether to install {uri-helm}[helm] on the bastion instance.
|true/false
|false

|===

== Calico

[stripes=odd,cols="1d,4d,3a,3a", options=header,width="100%"] 
|===
|Parameter
|Description
|Values
|Default

|calico_version
|Version of {uri-calico}[Calico] to install.
|
|3.9

|install_calico
|Whether to install {uri-calico}[Calico] as {uri-calico-policy}[pod network policy].
|true/false
|false
|===

== Kubernetes Metrics Server

[stripes=odd,cols="1d,4d,3a,3a", options=header,width="100%"] 
|===
|Parameter
|Description
|Values
|Default

|install_metricserver
|Whether to install {uri-metrics-server}[Kubernetes Metrics Server]. *Required* for {uri-kubernetes-hpa}[Horizontal Pod Autoscaling].
|true/false
|false
|===

== KMS integration

[stripes=odd,cols="1d,4d,3a,3a", options=header,width="100%"] 
|===
|Parameter
|Description
|Values
|Default

|use_encryption
|Whether to use {uri-oci-kms}[OCI KMS] to encrypt secrets.
|true/false
|false

|existing_key_id
|id of existing KMS key
|
|
